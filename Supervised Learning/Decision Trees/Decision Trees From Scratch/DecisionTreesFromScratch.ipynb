{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3a3bd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pydot\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e243918",
   "metadata": {},
   "outputs": [],
   "source": [
    "#node class an object of which represents a node of the tree\n",
    "class Node:\n",
    "    def __init__(self, split_on_feature, current_output):\n",
    "        #contains the value of the feature upon which the node is goin to be split, none indicates a leaf node\n",
    "        self.split_on_feature = split_on_feature\n",
    "        \n",
    "        #contains children nodes as a dictionary, key is the value of the feature upon which the node is split and value is the child node\n",
    "        self.children = {}\n",
    "        \n",
    "        #contains the class with current majority in the node\n",
    "        self.current_output = current_output\n",
    "        \n",
    "    def add_child(self, feature_value, node):\n",
    "        self.children[feature_value] = node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8291562e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the following implements the Decision Tree class\n",
    "class DecisionTreeClassifier:\n",
    "    def _init_(self):\n",
    "        self.root = None\n",
    "        \n",
    "    #counts the number of occurences of each class in the current subset of original data points\n",
    "    def frequency_counter(self, Y):\n",
    "        frequency = {}\n",
    "        for cls in Y:\n",
    "            if cls in frequency:\n",
    "                frequency[cls] += 1\n",
    "            else:\n",
    "                frequency[cls] = 1\n",
    "        return frequency\n",
    "                \n",
    "    #calculates the entropy/information gain for a single node\n",
    "    def entropy(self, Y):\n",
    "        frequency = self.frequency_counter(Y)\n",
    "        info = 0\n",
    "        total_instances = len(Y)\n",
    "        \n",
    "        for cls in frequency:\n",
    "            pi = frequency[cls]/total_instances\n",
    "            info += -(pi*math.log2(pi))\n",
    "            \n",
    "        return info\n",
    "    \n",
    "    #calculates the gain ratio achieved when a node is split upon a particular feature\n",
    "    def gain_ratio(self, X, Y, split_on_feature):\n",
    "        \n",
    "        entropy_before_splitting = self.entropy(Y)\n",
    "        entropy_after_splitting = 0\n",
    "        split_info = 0\n",
    "        \n",
    "        split_on_feature_values = set(X[:, split_on_feature])\n",
    "        \n",
    "        df = pd.DataFrame(X)\n",
    "        df[df.shape[1]] = Y\n",
    "        \n",
    "        total_instances = len(df)\n",
    "        for value in split_on_feature_values:\n",
    "            dfi = df[df[split_on_feature] == value]\n",
    "            current_instances = len(dfi)\n",
    "            entropy_after_splitting += ((current_instances/total_instances)*self.entropy(dfi.iloc[:, -1]))\n",
    "            split_info += (-((current_instances/total_instances) * math.log2(current_instances/total_instances)))\n",
    "            \n",
    "        if split_info == 0:\n",
    "            return math.inf\n",
    "        \n",
    "        info_gain = entropy_before_splitting - entropy_after_splitting\n",
    "        gain_ratio = (info_gain/split_info)\n",
    "        return gain_ratio\n",
    "    \n",
    "    #creates the decision tree recursively\n",
    "    def decision_tree(self, X, Y, features_left, classes, current_level, all_features):\n",
    "        \n",
    "        print('Level', current_level)\n",
    "        frequency = self.frequency_counter(Y)\n",
    "        \n",
    "        #############################################################################################################\n",
    "        \n",
    "        #base case - 1 when no features are left to split upon\n",
    "        if(len(features_left) == 0):\n",
    "            output = None\n",
    "            max_frequency = -math.inf\n",
    "            for cls in classes:\n",
    "                if cls not in frequency:\n",
    "                    print('Count of', cls, \"=\", 0)\n",
    "                else:\n",
    "                    if frequency[cls] > max_frequency:\n",
    "                        output = cls\n",
    "                        max_frequency = frequency[cls]\n",
    "                    print('Count of', cls, \"=\", frequency[cls])\n",
    "            \n",
    "            print('Current Entropy is =', self.entropy(Y))          \n",
    "            print('Reached leaf Node')\n",
    "            print()\n",
    "            return Node(None, output)\n",
    "        \n",
    "        #############################################################################################################\n",
    "        \n",
    "        #base case - 2 when we have reached a leaf node\n",
    "        if (len(set(Y)) == 1):\n",
    "            output = None\n",
    "            for cls in classes:\n",
    "                if cls in Y:\n",
    "                    output = cls\n",
    "                    print('Count of', cls, '=', len(Y))\n",
    "                else :\n",
    "                    print('Count of', cls, '=', 0)\n",
    "            \n",
    "            print('Current Entropy is =  0.0')\n",
    "            print('Reached leaf Node')\n",
    "            print()\n",
    "            return Node(None, output)\n",
    "\n",
    "        #############################################################################################################\n",
    "        \n",
    "        #calculating best feature to split upon i.e. feature with maximum gain ratio\n",
    "        max_gain_ratio = -math.inf\n",
    "        final_feature_to_split_upon = None\n",
    "        for i in features_left :\n",
    "            current_gain_ratio = self.gain_ratio(X, Y, i)\n",
    "            if current_gain_ratio > max_gain_ratio:\n",
    "                max_gain_ratio = current_gain_ratio\n",
    "                final_feature_to_split_upon = i\n",
    "\n",
    "        output = None\n",
    "        max_frequency = -math.inf\n",
    "\n",
    "        for cls in classes:\n",
    "            if cls not in frequency:\n",
    "                print('Count of', cls, '=', 0)\n",
    "            else:\n",
    "                if frequency[cls] > max_frequency:\n",
    "                    output = cls\n",
    "                    max_frequency = frequency[cls]\n",
    "                print('Count of', cls, '=', frequency[cls])\n",
    "     \n",
    "        print('Current Entropy is =', self.entropy(Y))\n",
    "        print('Splitting on feature' , all_features[final_feature_to_split_upon] , 'with gain ratio' , max_gain_ratio)\n",
    "        print()\n",
    "        \n",
    "        #############################################################################################################\n",
    "            \n",
    "        #splitting and calling on split recursively for every value of chosen feature\n",
    "        feature_values = set(X[:, final_feature_to_split_upon])\n",
    "        df = pd.DataFrame(X)\n",
    "        df[df.shape[1]] = Y\n",
    "\n",
    "        current_node = Node(final_feature_to_split_upon, output)\n",
    "\n",
    "        index = features_left.index(final_feature_to_split_upon)\n",
    "        features_left.remove(final_feature_to_split_upon)\n",
    "        \n",
    "        for value in feature_values:\n",
    "            dfi = df[df[final_feature_to_split_upon] == value]\n",
    "            \n",
    "            node = self.decision_tree(dfi.iloc[:, 0:-1].values, dfi.iloc[:, -1].values, features_left, classes, current_level + 1, all_features)\n",
    "            current_node.add_child(value, node)\n",
    "    \n",
    "        features_left.insert(index, final_feature_to_split_upon)\n",
    "        return current_node\n",
    "    \n",
    "    #function analogous to fit in scikit-learn\n",
    "    def fit(self, X, Y):\n",
    "        all_features = np.array([feature for feature in df.columns])\n",
    "        features = [i for i in range(len(X[0]))]\n",
    "        classes = set(Y)\n",
    "        level = 0\n",
    "        self.root = self.decision_tree(X, Y, features, classes, level, all_features)\n",
    "        \n",
    "    #function used to predict target value for a single data point \n",
    "    def predict_data_point(self, data, node):\n",
    "        if len(node.children) == 0:\n",
    "            return node.current_output\n",
    "\n",
    "        value = data[node.split_on_feature]       \n",
    "        if value not in node.children:\n",
    "            return node.current_output\n",
    "        \n",
    "        return self.predict_data_point(data, node.children[value])\n",
    "\n",
    "    #function analogous to predict of scikit-learn \n",
    "    def predict(self, X_test):\n",
    "        Y_predicted = np.array([0 for i in range(len(X_test))])\n",
    "        for i in range(len(X_test)):\n",
    "            Y_predicted[i] = self.predict_data_point(X_test[i], self.root)\n",
    "        return Y_predicted\n",
    "    \n",
    "    #function analogous to score of scikit-learn\n",
    "    def score(self, X_test, Y_test):\n",
    "        Y_predicted = self.predict(X_test)\n",
    "        score = ((Y_predicted == Y_test).sum())/len(Y_test)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd649b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function used to convert the decision tree to a dictionary\n",
    "def make_dict(node, features, classes, dictionary):\n",
    "    if(node.split_on_feature is None):\n",
    "        return classes[node.current_output]\n",
    "    else:\n",
    "        dictionary[features[node.split_on_feature]] = {}\n",
    "        for child in node.children.keys():\n",
    "            res = make_dict(node.children[child], features, classes, {})\n",
    "            dictionary[features[node.split_on_feature]][child] = res\n",
    "    return dictionary\n",
    "\n",
    "#function used to make the required graph of the decision tree using the dictionary created above\n",
    "def make_graph(graph, dictionary, parent_node = None):\n",
    "    for k in dictionary.keys():\n",
    "        if parent_node is not None:\n",
    "            from_name = parent_node.get_name().replace(\"\\\"\", \"\") + '_' + str(k)\n",
    "            from_label = str(k)\n",
    "\n",
    "            node_from = pydot.Node(from_name, label = from_label)\n",
    "            \n",
    "            graph.add_node(node_from)\n",
    "            graph.add_edge(pydot.Edge(parent_node, node_from))\n",
    "\n",
    "            if (isinstance(dictionary[k], dict)):\n",
    "                make_graph(graph, dictionary[k], node_from)\n",
    "\n",
    "            else:\n",
    "                to_name = str(k) + '_' + str(dictionary[k])\n",
    "                to_label = str(dictionary[k])\n",
    "\n",
    "                node_to = pydot.Node(to_name, label = to_label, shape = 'box')\n",
    "                \n",
    "                graph.add_node(node_to)\n",
    "                graph.add_edge(pydot.Edge(node_from, node_to))\n",
    "\n",
    "        else:\n",
    "            from_name =  str(k)\n",
    "            from_label = str(k)\n",
    "\n",
    "            node_from = pydot.Node(from_name, label = from_label)\n",
    "            \n",
    "            graph.add_node(node_from)\n",
    "            \n",
    "            make_graph(graph, dictionary[k], node_from)\n",
    "\n",
    "#function to plot the tree using the dictionary created above\n",
    "def plot_tree(decision_tree, name):\n",
    "    graph = pydot.Dot(graph_type = 'graph')\n",
    "    make_graph(graph, decision_tree)\n",
    "    graph.write_png(name + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93040db",
   "metadata": {},
   "source": [
    "# 1. Decision Tree for OR Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "023d6825",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[True, True, True], [False, True, True], [True, False, True], [False, False, False]]\n",
    "df = pd.DataFrame(data, columns = ['X1', 'X2', 'Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "728f2ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      X1     X2      Y\n",
       "0   True   True   True\n",
       "1  False   True   True\n",
       "2   True  False   True\n",
       "3  False  False  False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "546e9c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.iloc[:, :-1]\n",
    "Y_train = df.iloc[:, -1]\n",
    "Y_train.replace({False: 0, True: 1}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c54f2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 0\n",
      "Count of 0 = 1\n",
      "Count of 1 = 3\n",
      "Current Entropy is = 0.8112781244591328\n",
      "Splitting on feature X1 with gain ratio 0.31127812445913283\n",
      "\n",
      "Level 1\n",
      "Count of 0 = 1\n",
      "Count of 1 = 1\n",
      "Current Entropy is = 1.0\n",
      "Splitting on feature X2 with gain ratio 1.0\n",
      "\n",
      "Level 2\n",
      "Count of 0 = 1\n",
      "Count of 1 = 0\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 2\n",
      "Count of 0 = 0\n",
      "Count of 1 = 1\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 1\n",
      "Count of 0 = 0\n",
      "Count of 1 = 2\n",
      "Current Entropy is =  0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Accuracy: 100.0\n",
      "{'X1': {False: {'X2': {False: 'False', True: 'True'}}, True: 'True'}}\n"
     ]
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X_train.values, Y_train.values)\n",
    "score = classifier.score(X_train.values, Y_train.values)\n",
    "print('Accuracy:', score*100)\n",
    "\n",
    "features = ['X1', 'X2']\n",
    "classes = ['False', 'True']\n",
    "decision_tree = make_dict(classifier.root, features, classes, {})\n",
    "pprint(decision_tree)\n",
    "plot_tree(decision_tree, 'OR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccaf640",
   "metadata": {},
   "source": [
    "# 2. Decision Tree for Play Tennis Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb78bde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 0\n",
      "Count of 0 = 5\n",
      "Count of 1 = 9\n",
      "Current Entropy is = 0.9402859586706311\n",
      "Splitting on feature outlook with gain ratio 0.15642756242117528\n",
      "\n",
      "Level 1\n",
      "Count of 0 = 3\n",
      "Count of 1 = 2\n",
      "Current Entropy is = 0.9709505944546686\n",
      "Splitting on feature humidity with gain ratio 1.0\n",
      "\n",
      "Level 2\n",
      "Count of 0 = 3\n",
      "Count of 1 = 0\n",
      "Current Entropy is =  0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 2\n",
      "Count of 0 = 0\n",
      "Count of 1 = 2\n",
      "Current Entropy is =  0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 1\n",
      "Count of 0 = 0\n",
      "Count of 1 = 4\n",
      "Current Entropy is =  0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 1\n",
      "Count of 0 = 2\n",
      "Count of 1 = 3\n",
      "Current Entropy is = 0.9709505944546686\n",
      "Splitting on feature wind with gain ratio 1.0\n",
      "\n",
      "Level 2\n",
      "Count of 0 = 2\n",
      "Count of 1 = 0\n",
      "Current Entropy is =  0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 2\n",
      "Count of 0 = 0\n",
      "Count of 1 = 3\n",
      "Current Entropy is =  0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Accuracy: 100.0\n",
      "{'outlook': {'Overcast': 'Yes',\n",
      "             'Rain': {'wind': {'Strong': 'No', 'Weak': 'Yes'}},\n",
      "             'Sunny': {'humidity': {'High': 'No', 'Normal': 'Yes'}}}}\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('play_tennis.csv')\n",
    "df.drop('day', axis = 1, inplace = True)\n",
    "\n",
    "X_train = df.iloc[:, :-1].values\n",
    "Y_train = df.iloc[:, -1].replace({'Yes':1, 'No':0})\n",
    "\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "score = classifier.score(X_train, Y_train)\n",
    "print('Accuracy:', score*100)\n",
    "\n",
    "features = df.columns\n",
    "classes = ['No', 'Yes']\n",
    "decision_tree = make_dict(classifier.root, features, classes, {})\n",
    "pprint(decision_tree)\n",
    "plot_tree(decision_tree, 'play_tennis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "664364de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlook</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind</th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Mild</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Mild</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>Hot</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     outlook  temp humidity    wind play\n",
       "0      Sunny   Hot     High    Weak   No\n",
       "1      Sunny   Hot     High  Strong   No\n",
       "2   Overcast   Hot     High    Weak  Yes\n",
       "3       Rain  Mild     High    Weak  Yes\n",
       "4       Rain  Cool   Normal    Weak  Yes\n",
       "5       Rain  Cool   Normal  Strong   No\n",
       "6   Overcast  Cool   Normal  Strong  Yes\n",
       "7      Sunny  Mild     High    Weak   No\n",
       "8      Sunny  Cool   Normal    Weak  Yes\n",
       "9       Rain  Mild   Normal    Weak  Yes\n",
       "10     Sunny  Mild   Normal  Strong  Yes\n",
       "11  Overcast  Mild     High  Strong  Yes\n",
       "12  Overcast   Hot   Normal    Weak  Yes\n",
       "13      Rain  Mild     High  Strong   No"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e2c1cf",
   "metadata": {},
   "source": [
    "# 3. Decision Tree for Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06698ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_util(value, *limits):\n",
    "    if (limits[0] <= value < limits[1]):\n",
    "        return '[minimum, (minimum + mean)/2)'\n",
    "    elif (limits[1] <= value < limits[2]):\n",
    "        return '[(minimum + mean)/2, mean)'\n",
    "    elif (limits[2] <= value < limits[3]):\n",
    "        return '[mean, (mean + maximum)/2)'\n",
    "    elif (limits[3] <= value <= limits[4]):\n",
    "        return '[(mean + maximum)/2, maximum]'\n",
    "\n",
    "#function to convert the continuous values to categorical values\n",
    "def continuous_to_categorical(df, feature_name):\n",
    "    minimum = df[feature_name].min()\n",
    "    mean = df[feature_name].mean()\n",
    "    maximum = df[feature_name].max()\n",
    "    \n",
    "    #categories are assigned as follows\n",
    "    #category1 = [b1, b2)\n",
    "    #category2 = [b2, b3)\n",
    "    #category3 = [b3, b4)\n",
    "    #category4 = [b4, b5]\n",
    "    b1 = minimum\n",
    "    b2 = (minimum + mean)/2\n",
    "    b3 = mean\n",
    "    b4 = (mean + maximum)/2\n",
    "    b5 = maximum\n",
    "    \n",
    "    return df[feature_name].apply(ctc_util, args = (b1, b2, b3, b4, b5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccc6f858",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "df = pd.DataFrame(iris.data)\n",
    "df.columns = iris.feature_names\n",
    "\n",
    "df[df.columns[0]] = continuous_to_categorical(df, df.columns[0])\n",
    "df[df.columns[1]] = continuous_to_categorical(df, df.columns[1])\n",
    "df[df.columns[2]] = continuous_to_categorical(df, df.columns[2])\n",
    "df[df.columns[3]] = continuous_to_categorical(df, df.columns[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44e88a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(minimum + mean)/2, mean)</td>\n",
       "      <td>[mean, (mean + maximum)/2)</td>\n",
       "      <td>[minimum, (minimum + mean)/2)</td>\n",
       "      <td>[minimum, (minimum + mean)/2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[minimum, (minimum + mean)/2)</td>\n",
       "      <td>[(minimum + mean)/2, mean)</td>\n",
       "      <td>[minimum, (minimum + mean)/2)</td>\n",
       "      <td>[minimum, (minimum + mean)/2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[minimum, (minimum + mean)/2)</td>\n",
       "      <td>[mean, (mean + maximum)/2)</td>\n",
       "      <td>[minimum, (minimum + mean)/2)</td>\n",
       "      <td>[minimum, (minimum + mean)/2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[minimum, (minimum + mean)/2)</td>\n",
       "      <td>[mean, (mean + maximum)/2)</td>\n",
       "      <td>[minimum, (minimum + mean)/2)</td>\n",
       "      <td>[minimum, (minimum + mean)/2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[minimum, (minimum + mean)/2)</td>\n",
       "      <td>[mean, (mean + maximum)/2)</td>\n",
       "      <td>[minimum, (minimum + mean)/2)</td>\n",
       "      <td>[minimum, (minimum + mean)/2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>[mean, (mean + maximum)/2)</td>\n",
       "      <td>[(minimum + mean)/2, mean)</td>\n",
       "      <td>[mean, (mean + maximum)/2)</td>\n",
       "      <td>[(mean + maximum)/2, maximum]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>[mean, (mean + maximum)/2)</td>\n",
       "      <td>[minimum, (minimum + mean)/2)</td>\n",
       "      <td>[mean, (mean + maximum)/2)</td>\n",
       "      <td>[(mean + maximum)/2, maximum]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>[mean, (mean + maximum)/2)</td>\n",
       "      <td>[(minimum + mean)/2, mean)</td>\n",
       "      <td>[mean, (mean + maximum)/2)</td>\n",
       "      <td>[(mean + maximum)/2, maximum]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>[mean, (mean + maximum)/2)</td>\n",
       "      <td>[mean, (mean + maximum)/2)</td>\n",
       "      <td>[(mean + maximum)/2, maximum]</td>\n",
       "      <td>[(mean + maximum)/2, maximum]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>[mean, (mean + maximum)/2)</td>\n",
       "      <td>[(minimum + mean)/2, mean)</td>\n",
       "      <td>[mean, (mean + maximum)/2)</td>\n",
       "      <td>[mean, (mean + maximum)/2)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 sepal length (cm)               sepal width (cm)  \\\n",
       "0       [(minimum + mean)/2, mean)     [mean, (mean + maximum)/2)   \n",
       "1    [minimum, (minimum + mean)/2)     [(minimum + mean)/2, mean)   \n",
       "2    [minimum, (minimum + mean)/2)     [mean, (mean + maximum)/2)   \n",
       "3    [minimum, (minimum + mean)/2)     [mean, (mean + maximum)/2)   \n",
       "4    [minimum, (minimum + mean)/2)     [mean, (mean + maximum)/2)   \n",
       "..                             ...                            ...   \n",
       "145     [mean, (mean + maximum)/2)     [(minimum + mean)/2, mean)   \n",
       "146     [mean, (mean + maximum)/2)  [minimum, (minimum + mean)/2)   \n",
       "147     [mean, (mean + maximum)/2)     [(minimum + mean)/2, mean)   \n",
       "148     [mean, (mean + maximum)/2)     [mean, (mean + maximum)/2)   \n",
       "149     [mean, (mean + maximum)/2)     [(minimum + mean)/2, mean)   \n",
       "\n",
       "                 petal length (cm)               petal width (cm)  \n",
       "0    [minimum, (minimum + mean)/2)  [minimum, (minimum + mean)/2)  \n",
       "1    [minimum, (minimum + mean)/2)  [minimum, (minimum + mean)/2)  \n",
       "2    [minimum, (minimum + mean)/2)  [minimum, (minimum + mean)/2)  \n",
       "3    [minimum, (minimum + mean)/2)  [minimum, (minimum + mean)/2)  \n",
       "4    [minimum, (minimum + mean)/2)  [minimum, (minimum + mean)/2)  \n",
       "..                             ...                            ...  \n",
       "145     [mean, (mean + maximum)/2)  [(mean + maximum)/2, maximum]  \n",
       "146     [mean, (mean + maximum)/2)  [(mean + maximum)/2, maximum]  \n",
       "147     [mean, (mean + maximum)/2)  [(mean + maximum)/2, maximum]  \n",
       "148  [(mean + maximum)/2, maximum]  [(mean + maximum)/2, maximum]  \n",
       "149     [mean, (mean + maximum)/2)     [mean, (mean + maximum)/2)  \n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78b2ba2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 0\n",
      "Count of 0 = 37\n",
      "Count of 1 = 34\n",
      "Count of 2 = 41\n",
      "Current Entropy is = 1.5807197138422102\n",
      "Splitting on feature petal length (cm) with gain ratio 0.680231787985011\n",
      "\n",
      "Level 1\n",
      "Count of 0 = 0\n",
      "Count of 1 = 0\n",
      "Count of 2 = 24\n",
      "Current Entropy is =  0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 1\n",
      "Count of 0 = 37\n",
      "Count of 1 = 0\n",
      "Count of 2 = 0\n",
      "Current Entropy is =  0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 1\n",
      "Count of 0 = 0\n",
      "Count of 1 = 6\n",
      "Count of 2 = 0\n",
      "Current Entropy is =  0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 1\n",
      "Count of 0 = 0\n",
      "Count of 1 = 28\n",
      "Count of 2 = 17\n",
      "Current Entropy is = 0.9564574047992594\n",
      "Splitting on feature petal width (cm) with gain ratio 0.3518470770212301\n",
      "\n",
      "Level 2\n",
      "Count of 0 = 0\n",
      "Count of 1 = 0\n",
      "Count of 2 = 9\n",
      "Current Entropy is =  0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 2\n",
      "Count of 0 = 0\n",
      "Count of 1 = 3\n",
      "Count of 2 = 0\n",
      "Current Entropy is =  0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 2\n",
      "Count of 0 = 0\n",
      "Count of 1 = 25\n",
      "Count of 2 = 8\n",
      "Current Entropy is = 0.7990485210442682\n",
      "Splitting on feature sepal length (cm) with gain ratio 0.14662562110534788\n",
      "\n",
      "Level 3\n",
      "Count of 0 = 0\n",
      "Count of 1 = 2\n",
      "Count of 2 = 0\n",
      "Current Entropy is =  0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 3\n",
      "Count of 0 = 0\n",
      "Count of 1 = 0\n",
      "Count of 2 = 1\n",
      "Current Entropy is =  0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 3\n",
      "Count of 0 = 0\n",
      "Count of 1 = 7\n",
      "Count of 2 = 0\n",
      "Current Entropy is =  0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 3\n",
      "Count of 0 = 0\n",
      "Count of 1 = 16\n",
      "Count of 2 = 7\n",
      "Current Entropy is = 0.8865408928220899\n",
      "Splitting on feature sepal width (cm) with gain ratio 0.08767645528023384\n",
      "\n",
      "Level 4\n",
      "Count of 0 = 0\n",
      "Count of 1 = 3\n",
      "Count of 2 = 1\n",
      "Current Entropy is = 0.8112781244591328\n",
      "Reached leaf Node\n",
      "\n",
      "Level 4\n",
      "Count of 0 = 0\n",
      "Count of 1 = 9\n",
      "Count of 2 = 6\n",
      "Current Entropy is = 0.9709505944546686\n",
      "Reached leaf Node\n",
      "\n",
      "Level 4\n",
      "Count of 0 = 0\n",
      "Count of 1 = 4\n",
      "Count of 2 = 0\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Accuracy: 100.0\n",
      "{'petal length (cm)': {'[(mean + maximum)/2, maximum]': 'virginica',\n",
      "                       '[(minimum + mean)/2, mean)': 'versicolor',\n",
      "                       '[mean, (mean + maximum)/2)': {'petal width (cm)': {'[(mean + maximum)/2, maximum]': 'virginica',\n",
      "                                                                           '[(minimum + mean)/2, mean)': 'versicolor',\n",
      "                                                                           '[mean, (mean + maximum)/2)': {'sepal length (cm)': {'[(mean + maximum)/2, maximum]': 'versicolor',\n",
      "                                                                                                                                '[(minimum + mean)/2, mean)': 'versicolor',\n",
      "                                                                                                                                '[mean, (mean + maximum)/2)': {'sepal width (cm)': {'[(minimum + mean)/2, mean)': 'versicolor',\n",
      "                                                                                                                                                                                    '[mean, (mean + maximum)/2)': 'versicolor',\n",
      "                                                                                                                                                                                    '[minimum, (minimum + mean)/2)': 'versicolor'}},\n",
      "                                                                                                                                '[minimum, (minimum + mean)/2)': 'virginica'}}}},\n",
      "                       '[minimum, (minimum + mean)/2)': 'setosa'}}\n"
     ]
    }
   ],
   "source": [
    "X = df.values\n",
    "Y = iris.target\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state = 1)\n",
    "\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "score = classifier.score(X_test, Y_test)\n",
    "print('Accuracy:', score*100)\n",
    "\n",
    "features = iris.feature_names\n",
    "classes = iris.target_names\n",
    "decision_tree = make_dict(classifier.root, features, classes, {})\n",
    "pprint(decision_tree)\n",
    "plot_tree(decision_tree, 'iris')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
